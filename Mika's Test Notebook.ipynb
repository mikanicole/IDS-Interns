{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# __Project 1 - ENGL 3116__\n",
    "## Comparison of Detective Fiction to Psychological Fiction\n",
    "## Mika Mildenberger, George De Marigny, Abigail Mackessey\n",
    "### 2/17/2021\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in install.packages(\"udpipe\"):\n",
      "“installation of package ‘udpipe’ had non-zero exit status”\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"udpipe\")\n",
    "#Load our libraries\n",
    "library(tidyverse)\n",
    "library(tidytext)\n",
    "library(gutenbergr)\n",
    "library(udpipe)\n",
    "library(igraph)\n",
    "library(ggraph)\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we worked on the preliminary gathering and cleaning code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in data(\"stop_words\"):\n",
      "“data set ‘stop_words’ not found”\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in stop_words %>% filter(lexicon == \"SMART\"): could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in stop_words %>% filter(lexicon == \"SMART\"): could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "data(\"stop_words\") #load the stopwords data\n",
    "\n",
    "#filter for Smart words\n",
    "smart <- stop_words%>%\n",
    "  filter(lexicon ==\"SMART\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step was to find and locate both the detective corpus works and the psychological works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in gutenberg_subjects %>% filter(subject == \"Detective and mystery stories\"): could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in gutenberg_subjects %>% filter(subject == \"Detective and mystery stories\"): could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "#Finding the detective works:\n",
    "detective_PG <- gutenberg_subjects %>%\n",
    "  filter(subject == \"Detective and mystery stories\")\n",
    "\n",
    "#Locating and filtering metadata\n",
    "detective_PG_metadata <- inner_join(detective_PG, gutenberg_metadata)\n",
    "\n",
    "detective_PG_filtered <- detective_PG_metadata %>%\n",
    "  filter(language == \"en\") %>%\n",
    "  filter(has_text == TRUE)\n",
    "\n",
    "#Doing the same steps for the psychological corpus:\n",
    "\n",
    "psych_PG <- gutenberg_subjects%>%\n",
    "  filter(subject == \"Psychological fiction\")\n",
    "\n",
    "psych_PG_metadata <- inner_join(psych_PG, gutenberg_metadata)\n",
    "\n",
    "psych_PG_filtered <-psych_PG_metadata %>%\n",
    "  filter(language == \"en\") %>%\n",
    "  filter(has_text == TRUE)\n",
    "\n",
    "#Now set a seed to get the same data each time and locate random data for each corpus\n",
    "set.seed(1)\n",
    "\n",
    "#random novels generated\n",
    "detective_random <- sample_n(detective_PG_filtered, 40)\n",
    "psych_random <- sample_n(psych_PG_filtered, 40)\n",
    "\n",
    "#collect novel id numbers\n",
    "detective_random_id <- detective_random$gutenberg_id\n",
    "psych_random_id <- psych_random$gutenberg_id\n",
    "\n",
    "#load from Project Gutenberg\n",
    "detective_corpus <- gutenberg_download(detective_random_id, mirror = \"http://mirrors.xmission.com/gutenberg/\")\n",
    "psych_corpus <- gutenberg_download(psych_random_id, mirror = \"http://mirrors.xmission.com/gutenberg/\")\n",
    "\n",
    "#Lastly, tidy up the data\n",
    "detective_tidy <- detective_corpus%>%\n",
    "  unnest_tokens(paragraph, text)\n",
    "\n",
    "psych_tidy <- psych_corpus%>%\n",
    "  unnest_tokens(paragraph, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
